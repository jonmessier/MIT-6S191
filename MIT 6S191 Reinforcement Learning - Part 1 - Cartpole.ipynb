{"cells":[{"cell_type":"markdown","metadata":{"id":"jrI6q7RmWQam"},"source":["<table align=\"center\">\n","  <td align=\"center\"><a target=\"_blank\" href=\"http://introtodeeplearning.com\">\n","        <img src=\"https://i.ibb.co/Jr88sn2/mit.png\" style=\"padding-bottom:5px;\" />\n","      Visit MIT Deep Learning</a></td>\n","  <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/aamini/introtodeeplearning/blob/master/lab3/RL.ipynb\">\n","        <img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n","  <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/aamini/introtodeeplearning/blob/master/lab3/RL.ipynb\">\n","        <img src=\"https://i.ibb.co/xfJbPmL/github.png\"  height=\"70px\" style=\"padding-bottom:5px;\"  />View Source on GitHub</a></td>\n","</table>\n","\n","# Copyright Information"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"wkd375upWYok","executionInfo":{"status":"ok","timestamp":1702530697057,"user_tz":360,"elapsed":4,"user":{"displayName":"Jon Messier","userId":"10329250614884300997"}}},"outputs":[],"source":["# Copyright 2022 MIT 6.S191 Introduction to Deep Learning. All Rights Reserved.\n","#\n","# Licensed under the MIT License. You may not use this file except in compliance\n","# with the License. Use and/or modification of this code outside of 6.S191 must\n","# reference:\n","#\n","# Â© MIT 6.S191: Introduction to Deep Learning\n","# http://introtodeeplearning.com\n","#"]},{"cell_type":"markdown","metadata":{"id":"WoXYKhfZMHiw"},"source":["# Laboratory 3: Reinforcement Learning\n","\n","Reinforcement learning (RL) is a subset of machine learning which poses learning problems as interactions between agents and environments. It often assumes agents have no prior knowledge of a world, so they must learn to navigate environments by optimizing a reward function. Within an environment, an agent can take certain actions and receive feedback, in the form of positive or negative rewards, with respect to their decision. As such, an agent's feedback loop is somewhat akin to the idea of \"trial and error\", or the manner in which a child might learn to distinguish between \"good\" and \"bad\" actions.\n","\n","In practical terms, our RL agent will interact with the environment by taking an action at each timestep, receiving a corresponding reward, and updating its state according to what it has \"learned\".  \n","\n","![alt text](https://www.kdnuggets.com/images/reinforcement-learning-fig1-700.jpg)\n","\n","While the ultimate goal of reinforcement learning is to teach agents to act in the real, physical world, simulated environments -- like games and simulation engines -- provide a convenient proving ground for developing RL algorithms and agents.\n","\n","In previous labs, we have explored both supervised (with LSTMs, CNNs) and unsupervised / semi-supervised (with VAEs) learning tasks. Reinforcement learning is fundamentally different, in that we are training a deep learning algorithm to govern the actions of our RL agent, that is trying, within its environment, to find the optimal way to achieve a goal. The goal of training an RL agent is to determine the best next step to take to earn the greatest final payoff or return. In this lab, we focus on building a reinforcement learning algorithm to master two different environments with varying complexity.\n","\n","1.   **Cartpole**:   Balance a pole, protruding from a cart, in an upright position by only moving the base left or right. Environment with a low-dimensional observation space.\n","2.   [**Driving in VISTA**](https://www.mit.edu/~amini/pubs/pdf/learning-in-simulation-vista.pdf): Learn a driving control policy for an autonomous vehicle, end-to-end from raw pixel inputs and entirely in the data-driven simulation environment of VISTA. Environment with a high-dimensional observation space -- learning directly from raw pixels.\n","\n","Let's get started! First we'll import TensorFlow, the course package, and some dependencies.\n"]},{"cell_type":"markdown","source":["## Package Imports"],"metadata":{"id":"Jpxihui_woOZ"}},{"cell_type":"code","source":["# Import Tensorflow 2.0\n","#%tensorflow_version 2.x\n","import tensorflow.compat.v2 as tf\n","import tensorflow_probability as tfp"],"metadata":{"id":"WV3R3YRc3er8","executionInfo":{"status":"ok","timestamp":1702530701357,"user_tz":360,"elapsed":4304,"user":{"displayName":"Jon Messier","userId":"10329250614884300997"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"KR9QHuleJ9Bh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702530722636,"user_tz":360,"elapsed":9668,"user":{"displayName":"Jon Messier","userId":"10329250614884300997"}},"outputId":"8594b262-46c6-44ad-b351-08fd51d60dfb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Installing MIT deep learning package... Done\n"]}],"source":["gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    for gpu in gpus:\n","        tf.config.experimental.set_memory_growth(gpu, True)\n","\n","# Download and import the MIT 6.S191 package\n","!printf \"Installing MIT deep learning package... \"\n","!pip install --upgrade git+https://github.com/aamini/introtodeeplearning.git &> /dev/null\n","!echo \"Done\""]},{"cell_type":"code","execution_count":4,"metadata":{"id":"EvdePP-VyVWp","executionInfo":{"status":"ok","timestamp":1702530754524,"user_tz":360,"elapsed":29263,"user":{"displayName":"Jon Messier","userId":"10329250614884300997"}}},"outputs":[],"source":["#Install some dependencies for visualizing the agents\n","!apt-get install -y xvfb python-opengl x11-utils &> /dev/null\n","!pip install gym pyvirtualdisplay scikit-video ffio pyrender &> /dev/null\n","!pip install tensorflow_probability==0.12.0 &> /dev/null\n","import os\n","os.environ['PYOPENGL_PLATFORM'] = 'egl'\n","\n","import numpy as np\n","import matplotlib, cv2\n","import matplotlib.pyplot as plt\n","import base64, io, os, time, gym\n","import IPython, functools\n","import time\n","from tqdm import tqdm\n","\n","\n","import mitdeeplearning as mdl"]},{"cell_type":"markdown","metadata":{"id":"zmrHSiXKTXTY"},"source":["Before we dive in, let's take a step back and outline our approach, which is generally applicable to reinforcement learning problems in general:\n","\n","1. **Initialize our environment and our agent**: here we will describe the different observations and actions the agent can make in the environemnt.\n","2. **Define our agent's memory**: this will enable the agent to remember its past actions, observations, and rewards.\n","3. **Define a reward function**: describes the reward associated with an action or sequence of actions.\n","4. **Define the learning algorithm**: this will be used to reinforce the agent's good behaviors and discourage bad behaviors.\n"]},{"cell_type":"markdown","metadata":{"id":"UT7YL8KBJIIc"},"source":["# Part 1: Cartpole\n","\n","## 3.1 Define the Cartpole environment and agent\n","\n","### Environment\n","\n","In order to model the environment for the Cartpole task, we'll be using a toolkit developed by OpenAI called [OpenAI Gym](https://gym.openai.com/). It provides several pre-defined environments for training and testing reinforcement learning agents, including those for classic physics control tasks, Atari video games, and robotic simulations. To access the Cartpole environment, we can use `env = gym.make(\"CartPole-v0\")`, which we gained access to when we imported the `gym` package. We can instantiate different [environments](https://gym.openai.com/envs/#classic_control) by passing the enivronment name to the `make` function.\n","\n","One issue we might experience when developing RL algorithms is that many aspects of the learning process are inherently random: initializing game states, changes in the environment, and the agent's actions. As such, it can be helpful to set a initial \"seed\" for the environment to ensure some level of reproducibility. Much like you might use `numpy.random.seed`, we can call the comparable function in gym, `seed`, with our defined environment to ensure the environment's random variables are initialized the same each time."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"quv9SC0iIYFm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702530804406,"user_tz":360,"elapsed":302,"user":{"displayName":"Jon Messier","userId":"10329250614884300997"}},"outputId":"330d5244-e3ad-4897-ae27-7bf18188ef3b"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n","/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n","/usr/local/lib/python3.10/dist-packages/gym/core.py:256: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n","  deprecation(\n"]},{"output_type":"execute_result","data":{"text/plain":["[1]"]},"metadata":{},"execution_count":5}],"source":["### Instantiate the Cartpole environment ###\n","\n","env = gym.make(\"CartPole-v1\")\n","env.seed(1)"]},{"cell_type":"markdown","metadata":{"id":"mhEITUcKK455"},"source":["In Cartpole, a pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The pole starts upright, and the goal is to prevent it from falling over. The system is controlled by applying a force of +1 or -1 to the cart. A reward of +1 is provided for every timestep that the pole remains upright. The episode ends when the pole is more than 15 degrees from vertical, or the cart moves more than 2.4 units from the center of the track. A visual summary of the cartpole environment is depicted below:\n","\n","<img width=\"400px\" src=\"https://danielpiedrahita.files.wordpress.com/2017/02/cart-pole.png\"></img>\n","\n","Given this setup for the environment and the objective of the game, we can think about: 1) what observations help define the environment's state; 2) what actions the agent can take.\n","\n","First, let's consider the observation space. In this Cartpole environment our observations are:\n","\n","1. Cart position\n","2. Cart velocity\n","3. Pole angle\n","4. Pole rotation rate\n","\n","We can confirm the size of the space by querying the environment's observation space:\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"UVJaEcbdIX82","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702530808101,"user_tz":360,"elapsed":275,"user":{"displayName":"Jon Messier","userId":"10329250614884300997"}},"outputId":"66cbdb75-7797-40b6-b670-9be7cb9d2b49"},"outputs":[{"output_type":"stream","name":"stdout","text":["Environment has observation space = Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n"]}],"source":["n_observations = env.observation_space\n","print(\"Environment has observation space =\", n_observations)"]},{"cell_type":"markdown","metadata":{"id":"ZibGgjrALgPM"},"source":["Second, we consider the action space. At every time step, the agent can move either right or left. Again we can confirm the size of the action space by querying the environment:"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"qc9SIPxBIXrm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702530809669,"user_tz":360,"elapsed":7,"user":{"displayName":"Jon Messier","userId":"10329250614884300997"}},"outputId":"8c07e0ce-d082-4468-c0ea-832fb3b7e8f6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of possible actions that the agent can choose from = 2\n"]}],"source":["n_actions = env.action_space.n\n","print(\"Number of possible actions that the agent can choose from =\", n_actions)"]},{"cell_type":"markdown","metadata":{"id":"pPfHME8aRKkb"},"source":["### Cartpole agent\n","\n","Now that we have instantiated the environment and understood the dimensionality of the observation and action spaces, we are ready to define our agent. In deep reinforcement learning, a deep neural network defines the agent. This network will take as input an observation of the environment and output the probability of taking each of the possible actions. Since Cartpole is defined by a low-dimensional observation space, a simple feed-forward neural network should work well for our agent. We will define this using the `Sequential` API.\n"]},{"cell_type":"markdown","source":["#### `def create_cartpole_model()`"],"metadata":{"id":"ZWKGQTHQwRZ9"}},{"cell_type":"code","execution_count":8,"metadata":{"id":"W-o_XK4oQ4eu","executionInfo":{"status":"ok","timestamp":1702530818044,"user_tz":360,"elapsed":2858,"user":{"displayName":"Jon Messier","userId":"10329250614884300997"}}},"outputs":[],"source":["### Define the Cartpole agent ###\n","\n","# Defines a feed-forward neural network\n","def create_cartpole_model():\n","    model = tf.keras.models.Sequential([\n","        # First Dense layer\n","        tf.keras.layers.Dense(units=32, activation='relu'),\n","\n","        # TODO: Define the last Dense layer, which will provide the network's output.\n","        # Think about the space the agent needs to act in!\n","        # ['''TODO''' Dense layer to output action probabilities]\n","        #n_actions = 2, but instead of hardcoding it, leave it tied to the variable for future use\n","        #tf.keras.layers.Dense(units=n_actions, activation='softmax')\n","        tf.keras.layers.Dense(units=n_actions, activation=None)\n","    ])\n","    return model\n","\n","cartpole_model = create_cartpole_model()"]},{"cell_type":"markdown","metadata":{"id":"d5D5NSIYS2IW"},"source":["Now that we have defined the core network architecture, we will define an *action function* that executes a forward pass through the network, given a set of observations, and samples from the output. This sampling from the output probabilities will be used to select the next action for the agent. We will also add support so that the `choose_action` function can handle either a single observation or a batch of observations.\n","\n","**Critically, this action function is totally general -- we will use this function for learning control algorithms for Cartpole, but it is applicable to other RL tasks, as well!**"]},{"cell_type":"markdown","source":["#### `def choose_action`"],"metadata":{"id":"HW65iKkev4sS"}},{"cell_type":"code","execution_count":11,"metadata":{"id":"E_vVZRr8Q4R_","executionInfo":{"status":"ok","timestamp":1702531554147,"user_tz":360,"elapsed":240,"user":{"displayName":"Jon Messier","userId":"10329250614884300997"}}},"outputs":[],"source":["### Define the agent's action function ###\n","\n","# Function that takes observations as input, executes a forward pass through model,\n","#   and outputs a sampled action.\n","# Arguments:\n","#   model: the network that defines our agent\n","#   observation: observation(s) which is/are fed as input to the model\n","#   single: flag as to whether we are handling a single observation or batch of\n","#     observations, provided as an np.array\n","# Returns:\n","#   action: choice of agent action\n","def choose_action(model, observation, single=True):\n","    # add batch dimension to the observation if only a single example was provided\n","    observation = np.expand_dims(observation, axis=0) if single else observation\n","\n","    #feed the observations through the model to predict the log probabilities of each possible action.\n","    logits = model.predict(observation)\n","\n","    # Choose an action from the categorical distribution defined by the log probabilities of each possible action.\n","    action = tf.random.categorical(logits, num_samples=1)\n","    action = action.numpy().flatten()\n","\n","    return action[0] if single else action"]},{"cell_type":"markdown","metadata":{"id":"_tR9uAWcTnkr"},"source":["## 3.2 Define the agent's memory\n","\n","Now that we have instantiated the environment and defined the agent network architecture and action function, we are ready to move on to the next step in our RL workflow:\n","1. **Initialize our environment and our agent**: here we will describe the different observations and actions the agent can make in the environemnt.\n","2. **Define our agent's memory**: this will enable the agent to remember its past actions, observations, and rewards.\n","3. **Define the learning algorithm**: this will be used to reinforce the agent's good behaviors and discourage bad behaviors.\n","\n","In reinforcement learning, training occurs alongside the agent's acting in the environment; an *episode* refers to a sequence of actions that ends in some terminal state, such as the pole falling down or the cart crashing. The agent will need to remember all of its observations and actions, such that once an episode ends, it can learn to \"reinforce\" the good actions and punish the undesirable actions via training. Our first step is to define a simple `Memory` buffer that contains the agent's observations, actions, and received rewards from a given episode. We will also add support to combine a list of `Memory` objects into a single `Memory`. This will be very useful for batching, which will help you accelerate training later on in the lab.\n","\n","**Once again, note the modularity of this memory buffer -- it can and will be applied to other RL tasks as well!**"]},{"cell_type":"markdown","source":["### `class Memory`"],"metadata":{"id":"41w_6wS-vxHb"}},{"cell_type":"code","execution_count":12,"metadata":{"id":"8MM6JwXVQ4JG","executionInfo":{"status":"ok","timestamp":1702531563118,"user_tz":360,"elapsed":582,"user":{"displayName":"Jon Messier","userId":"10329250614884300997"}}},"outputs":[],"source":["### Agent Memory ###\n","\n","class Memory:\n","    def __init__(self):\n","        self.clear()\n","\n","  # Resets/restarts the memory buffer\n","    def clear(self):\n","        self.observations = []\n","        self.actions = []\n","        self.rewards = []\n","\n","  # Add observations, actions, rewards to memory\n","    def add_to_memory(self, new_observation, new_action, new_reward):\n","        self.observations.append(new_observation)\n","\n","        # update the list of actions with new action\n","        self.actions.append(new_action)\n","        # update the list of rewards with new reward\n","        self.rewards.append(new_reward)\n","\n","    def __len__(self):\n","        return len(self.actions)\n","\n","# Instantiate a single Memory buffer\n","memory = Memory()"]},{"cell_type":"markdown","metadata":{"id":"D4YhtPaUVj5m"},"source":["## 3.3 Reward function\n","\n","We're almost ready to begin the learning algorithm for our agent! The next step is to compute the rewards of our agent as it acts in the environment. Since we (and the agent) is uncertain about if and when the game or task will end (i.e., when the pole will fall), it is useful to emphasize getting rewards **now** rather than later in the future -- this is the idea of discounting. This is a similar concept to discounting money in the case of interest. Recall from lecture, we use reward discount to give more preference at getting rewards now rather than later in the future. The idea of discounting rewards is similar to discounting money in the case of interest.\n","\n","To compute the expected cumulative reward, known as the **return**, at a given timestep in a learning episode, we sum the discounted rewards expected at that time step $t$, within a learning episode, and projecting into the future. We define the return (cumulative reward) at a time step $t$, $R_{t}$ as:\n","\n",">$R_{t}=\\sum_{k=0}^\\infty\\gamma^kr_{t+k}$\n","\n","where  $0 < \\gamma < 1$ is the discount factor and $r_{t}$ is the reward at time step $t$, and the index $k$ increments projection into the future within a single learning episode. Intuitively, you can think of this function as depreciating any rewards received at later time steps, which will force the agent prioritize getting rewards now. Since we can't extend episodes to infinity, in practice the computation will be limited to the number of timesteps in an episode -- after that the reward is assumed to be zero.\n","\n","Take note of the form of this sum -- we'll have to be clever about how we implement this function. Specifically, we'll need to initialize an array of zeros, with length of the number of time steps, and fill it with the real discounted reward values as we loop through the rewards from the episode, which will have been saved in the agents memory. What we ultimately care about is which actions are better relative to other actions taken in that episode -- so, we'll normalize our computed rewards, using the mean and standard deviation of the rewards across the learning episode.\n","\n","We will use this definition of the reward function in both parts of the lab so make sure you have it executed!\n"]},{"cell_type":"markdown","source":["#### `def normalize`"],"metadata":{"id":"8mqASoa8ykX-"}},{"cell_type":"markdown","source":["#### `def discount_rewards`"],"metadata":{"id":"O4mL3KTMy6Nr"}},{"cell_type":"code","execution_count":13,"metadata":{"id":"5_Q2OFYtQ32X","executionInfo":{"status":"ok","timestamp":1702531990778,"user_tz":360,"elapsed":284,"user":{"displayName":"Jon Messier","userId":"10329250614884300997"}}},"outputs":[],"source":["### Reward function ###\n","\n","# Helper function that normalizes an np.array x\n","def normalize(x):\n","    x -= np.mean(x)\n","    x /= np.std(x)\n","    return x.astype(np.float32)\n","\n","# Compute normalized, discounted, cumulative rewards (i.e., return)\n","# Arguments:\n","#   rewards: reward at timesteps in episode\n","#   gamma: discounting factor\n","# Returns:\n","#   normalized discounted reward\n","def discount_rewards(rewards, gamma=0.95):\n","    discounted_rewards = np.zeros_like(rewards)\n","    R = 0\n","    for t in reversed(range(0, len(rewards))):\n","        # update the total discounted reward\n","        R = R * gamma + rewards[t]\n","        discounted_rewards[t] = R\n","\n","    return normalize(discounted_rewards)"]},{"cell_type":"markdown","metadata":{"id":"QzbY-mjGYcmt"},"source":["## 3.4 Learning algorithm\n","\n","Now we can start to define the learing algorithm which will be used to reinforce good behaviors of the agent and discourage bad behaviours. In this lab, we will focus on *policy gradient* methods which aim to **maximize** the likelihood of actions that result in large rewards. Equivalently, this means that we want to **minimize** the negative likelihood of these same actions. We achieve this by simply **scaling** the probabilities by their associated rewards -- effectively amplifying the likelihood of actions that resujlt in large rewards.\n","\n","Since the log function is monotonically increasing, this means that minimizing **negative likelihood** is equivalent to minimizing **negative log-likelihood**.  Recall that we can easily compute the negative log-likelihood of a discrete action by evaluting its [softmax cross entropy](https://www.tensorflow.org/api_docs/python/tf/nn/sparse_softmax_cross_entropy_with_logits). Like in supervised learning, we can use stochastic gradient descent methods to achieve the desired minimization.\n","\n","Let's begin by defining the loss function."]},{"cell_type":"markdown","source":["### `def compute_loss`"],"metadata":{"id":"fmfcIQHP0V_P"}},{"cell_type":"code","execution_count":14,"metadata":{"id":"fsgZ3IDCY_Zn","executionInfo":{"status":"ok","timestamp":1702532244427,"user_tz":360,"elapsed":303,"user":{"displayName":"Jon Messier","userId":"10329250614884300997"}}},"outputs":[],"source":["### Loss function ###\n","\n","# Arguments:\n","#   logits: network's predictions for actions to take\n","#   actions: the actions the agent took in an episode\n","#   rewards: the rewards the agent received in an episode\n","# Returns:\n","#   loss\n","def compute_loss(logits, actions, rewards):\n","    # complete the function call to compute the negative log probabilities\n","    neg_logprob = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logits, labels=actions)\n","\n","    # scale the negative log probability by the rewards\n","    loss = tf.reduce_mean(neg_logprob*rewards)\n","    return loss"]},{"cell_type":"markdown","source":["### `def train_step`"],"metadata":{"id":"dXK6WQpX0h_z"}},{"cell_type":"markdown","source":["### TODO - Add clipping function"],"metadata":{"id":"temCi0XF0-rV"}},{"cell_type":"markdown","metadata":{"id":"Rr5vQ9fqbPpp"},"source":["Now let's use the loss function to define a training step of our learning algorithm. This is a very generalizable definition which we will use"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"_50ada7nbZ7L","executionInfo":{"status":"ok","timestamp":1702532253187,"user_tz":360,"elapsed":568,"user":{"displayName":"Jon Messier","userId":"10329250614884300997"}}},"outputs":[],"source":["### Training step (forward and backpropagation) ###\n","\n","def train_step(model, loss_function, optimizer, observations, actions, discounted_rewards, custom_fwd_fn=None):\n","    with tf.GradientTape() as tape:\n","        # Forward propagate through the agent network\n","        if custom_fwd_fn is not None:\n","            prediction = custom_fwd_fn(observations)\n","        else:\n","            prediction = model(observations)\n","\n","        # call the compute_loss function to compute the loss\n","\n","        loss = compute_loss(prediction, actions, discounted_rewards)\n","\n","    '''run backpropagation to minimize the loss using the tape.gradient method.\n","       Unlike supervised learning, RL is *extremely* noisy, so you will benefit\n","       from additionally clipping your gradients to avoid falling into\n","       dangerous local minima. After computing your gradients try also clipping\n","       by a global normalizer. Try different clipping values, usually clipping\n","       between 0.5 and 5 provides reasonable results. '''\n","\n","    grads = tape.gradient(loss, model.trainable_variables)\n","\n","    #update after everything is working\n","    # grads, _ = tf.clip_by_global_norm(grads, 2)\n","    optimizer.apply_gradients(zip(grads, model.trainable_variables))"]},{"cell_type":"markdown","metadata":{"id":"XsjKXh6BcgjR"},"source":["## 3.5 Run cartpole!\n","\n","Having had no prior knowledge of the environment, the agent will begin to learn how to balance the pole on the cart based only on the feedback received from the environment! Having defined how our agent can move, how it takes in new observations, and how it updates its state, we'll see how it gradually learns a policy of actions to optimize balancing the pole as long as possible. To do this, we'll track how the rewards evolve as a function of training -- how should the rewards change as training progresses?"]},{"cell_type":"markdown","source":["### Training variables"],"metadata":{"id":"SVLUdTaR1WD7"}},{"cell_type":"code","execution_count":16,"metadata":{"id":"-hZ7E6JOJ9Bn","executionInfo":{"status":"ok","timestamp":1702532378396,"user_tz":360,"elapsed":254,"user":{"displayName":"Jon Messier","userId":"10329250614884300997"}}},"outputs":[],"source":["## Training parameters ##\n","## Re-run this cell to restart training from scratch ##\n","\n","#Learning rate and optimizer\n","learning_rate = .001\n","\n","#optimizer\n","optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","\n","# instantiate cartpole agent\n","cartpole_model = create_cartpole_model()\n","\n","# to track our progress\n","smoothed_reward = mdl.util.LossHistory(smoothing_factor=0.95)\n","plotter = mdl.util.PeriodicPlotter(sec=2, xlabel='Iterations', ylabel='Rewards')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XmOzc2rrcn8Q","scrolled":false,"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"b31b5928-5c0a-462e-f241-8c84c8549af4"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 1s 550ms/step\n","1/1 [==============================] - 2s 2s/step\n","1/1 [==============================] - 3s 3s/step\n","1/1 [==============================] - 3s 3s/step\n","1/1 [==============================] - 3s 3s/step\n","1/1 [==============================] - 3s 3s/step\n","1/1 [==============================] - 6s 6s/step\n","1/1 [==============================] - 40s 40s/step\n"]}],"source":["## Cartpole training! ##\n","## Note: stoping and restarting this cell will pick up training where you\n","#        left off. To restart training you need to rerun the cell above as\n","#        well (to re-initialize the model and optimizer)\n","\n","if hasattr(tqdm, '_instances'): tqdm._instances.clear() # clear if it exists\n","\n","#Changed from 500 to 100\n","for i_episode in range(1000):\n","\n","    plotter.plot(smoothed_reward.get())\n","    # Restart the environment\n","    observation = env.reset()\n","    memory.clear()\n","\n","    while True:\n","        # using our observation, choose an action and take it in the environment\n","        action = choose_action(cartpole_model, observation)\n","        next_observation, reward, done, info = env.step(action)\n","        # add to memory\n","        memory.add_to_memory(observation, action, reward)\n","\n","        # is the episode over? did you crash or do so well that you're done?\n","        if done:\n","            # determine total reward and keep a record of this\n","            total_reward = sum(memory.rewards)\n","            smoothed_reward.append(total_reward)\n","\n","            # initiate training - remember we don't know anything about how the\n","            #   agent is doing until it has crashed!\n","            g = train_step(cartpole_model, compute_loss, optimizer,\n","                       observations=np.vstack(memory.observations),\n","                       actions=np.array(memory.actions),\n","                       discounted_rewards = discount_rewards(memory.rewards))\n","\n","            # reset the memory\n","            memory.clear()\n","            break\n","        # update our observatons\n","        observation = next_observation"]},{"cell_type":"markdown","source":["## Save data to video"],"metadata":{"id":"jm_UIqts17sO"}},{"cell_type":"markdown","metadata":{"id":"mkcUtGF1VE-K"},"source":["To get a sense of how our agent did, we can save a video of the trained model working on balancing the pole. Realize that this is a brand new environment that the agent has not seen before!\n","\n","Let's display the saved video to watch how our agent did!\n"]},{"cell_type":"markdown","source":["### Install virtual display and xvfb structure"],"metadata":{"id":"qJCbM3zY2O-v"}},{"cell_type":"code","source":["#Install virtual display and xvfb file structure.\n","!pip install pyvirtualdisplay\n","!apt update\n","!apt install xvfb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"__1B2NL5Loyi","executionInfo":{"status":"ok","timestamp":1702492883639,"user_tz":360,"elapsed":21545,"user":{"displayName":"Jon Messier","userId":"10329250614884300997"}},"outputId":"322a1a86-9579-4f3a-8b8b-79674d15b986"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.10/dist-packages (3.0)\n","Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n","Hit:3 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n","Hit:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:5 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:6 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:7 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n","Hit:8 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:9 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n","Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [634 kB]\n","Hit:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,036 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,598 kB]\n","Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,321 kB]\n","Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,568 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,304 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,596 kB]\n","Fetched 9,290 kB in 2s (4,761 kB/s)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","24 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n","  xserver-common\n","The following NEW packages will be installed:\n","  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n","  xserver-common xvfb\n","0 upgraded, 9 newly installed, 0 to remove and 24 not upgraded.\n","Need to get 7,813 kB of archives.\n","After this operation, 11.9 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.5 [28.2 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.5 [863 kB]\n","Fetched 7,813 kB in 1s (7,729 kB/s)\n","Selecting previously unselected package libfontenc1:amd64.\n","(Reading database ... 120903 files and directories currently installed.)\n","Preparing to unpack .../0-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n","Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n","Selecting previously unselected package libxfont2:amd64.\n","Preparing to unpack .../1-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n","Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n","Selecting previously unselected package libxkbfile1:amd64.\n","Preparing to unpack .../2-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n","Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n","Selecting previously unselected package x11-xkb-utils.\n","Preparing to unpack .../3-x11-xkb-utils_7.7+5build4_amd64.deb ...\n","Unpacking x11-xkb-utils (7.7+5build4) ...\n","Selecting previously unselected package xfonts-encodings.\n","Preparing to unpack .../4-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n","Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n","Selecting previously unselected package xfonts-utils.\n","Preparing to unpack .../5-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n","Unpacking xfonts-utils (1:7.7+6build2) ...\n","Selecting previously unselected package xfonts-base.\n","Preparing to unpack .../6-xfonts-base_1%3a1.0.5_all.deb ...\n","Unpacking xfonts-base (1:1.0.5) ...\n","Selecting previously unselected package xserver-common.\n","Preparing to unpack .../7-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.5_all.deb ...\n","Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.5) ...\n","Selecting previously unselected package xvfb.\n","Preparing to unpack .../8-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.5_amd64.deb ...\n","Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.5) ...\n","Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n","Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n","Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n","Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n","Setting up x11-xkb-utils (7.7+5build4) ...\n","Setting up xfonts-utils (1:7.7+6build2) ...\n","Setting up xfonts-base (1:1.0.5) ...\n","Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.5) ...\n","Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.5) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n"]}]},{"cell_type":"markdown","source":["### `def save_video`"],"metadata":{"id":"I5T92PRR2BTT"}},{"cell_type":"code","source":["def save_video_of_model(model, env_name, suffix=\"\"):\n","    import skvideo.io\n","    from pyvirtualdisplay import Display\n","    display = Display(visible=0, size=(400, 300))\n","    display.start()\n","\n","    env = gym.make(env_name)\n","    obs = env.reset()\n","    prev_obs = obs\n","\n","    filename = env_name + suffix + \".mp4\"\n","    output_video = skvideo.io.FFmpegWriter(filename)\n","\n","    counter = 0\n","    done = False\n","    while not done:\n","        frame = env.render(mode='rgb_array')\n","        output_video.writeFrame(frame)\n","\n","        if \"CartPole\" in env_name:\n","            input_obs = obs\n","        elif \"Pong\" in env_name:\n","            input_obs = pong_change(prev_obs, obs)\n","        else:\n","            raise ValueError(f\"Unknown env for saving: {env_name}\")\n","\n","        action = model(np.expand_dims(input_obs, 0)).numpy().argmax()\n","\n","        prev_obs = obs\n","        obs, reward, done, info = env.step(action)\n","        counter += 1\n","\n","    output_video.close()\n","    print(\"Successfully saved {} frames into {}!\".format(counter, filename))\n","    return filename"],"metadata":{"id":"B12tCJuyA98G"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PAYBkv6Zbk0J","scrolled":true,"executionInfo":{"status":"error","timestamp":1702492972034,"user_tz":360,"elapsed":615,"user":{"displayName":"Jon Messier","userId":"10329250614884300997"}},"colab":{"base_uri":"https://localhost:8080/","height":233},"outputId":"cb2fe066-f6ca-4acc-b401-b9534ad0a2a8"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-518831ea0ff5>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Agg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msaved_cartpole\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_video_of_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcartpole_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CartPole-v1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Manually save file to disk and watch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'cartpole_model' is not defined"]}],"source":["matplotlib.use('Agg')\n","saved_cartpole = save_video_of_model(cartpole_model, \"CartPole-v1\")\n","\n","#Manually save file to disk and watch"]},{"cell_type":"markdown","source":["## TODO: Play video"],"metadata":{"id":"6XgwZQb73Bnt"}},{"cell_type":"markdown","source":["### TODO : `def play_video`"],"metadata":{"id":"IKfQrJBu2aGy"}},{"cell_type":"code","source":["from pyvirtualdisplay import Display\n","display = Display(visible=0, size=(400, 300))\n","display.start()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6F7jZdcYKVYA","executionInfo":{"status":"ok","timestamp":1702492884760,"user_tz":360,"elapsed":1129,"user":{"displayName":"Jon Messier","userId":"10329250614884300997"}},"outputId":"31844ec1-9847-4b77-e1b1-6de083ec8913"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyvirtualdisplay.display.Display at 0x7c92734fb460>"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["def play_video(filename, width=None):\n","    encoded = base64.b64encode(io.open(filename, 'r+b').read())\n","    video_width = 'width=\"' + str(width) + '\"' if width is not None else ''\n","    embedded = HTML(data='''\n","        <video controls {0}>\n","            <source src=\"data:video/mp4;base64,{1}\" type=\"video/mp4\" />\n","        </video>'''.format(video_width, encoded.decode('ascii')))\n","\n","    return embedded"],"metadata":{"id":"iV0MII4CBNqn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CSbVNDpaVb3_"},"source":["How does the agent perform? Could you train it for shorter amounts of time and still perform well? Do you think that training longer would help even more?"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/aamini/introtodeeplearning/blob/master/xtra_labs/autonomous_driving/RL.ipynb","timestamp":1702309064702}],"gpuType":"V100","toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}